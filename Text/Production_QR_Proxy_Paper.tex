\documentclass[11pt]{article}
\usepackage{graphicx}
\graphicspath{{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/}}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{tabularx}
\usepackage{mathrsfs}
\usepackage{subfigure}
\usepackage{color}
\usepackage{lscape}
\usepackage{longtable}
\usepackage{bm}
\usepackage{bbm}
\usepackage{chngcntr}
\usepackage{setspace}
\usepackage{caption}
\usepackage{float}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{fancyvrb}
\usepackage{enumitem}
\usepackage[multiple]{footmisc}
\newtheorem{assump}{Assumption}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]


\usepackage[multiple]{footmisc}

%Set margins and text size
\setlength{\textwidth}{6.5in} \setlength{\textheight}{8.8in}
\setlength{\topmargin}{-0.5in}
\setlength{\oddsidemargin}{-0.01in}{}
\setlength{\parskip}{1.6mm}
\parskip=.06in
{}
%Some useful short-cuts
\def\argmax{\mathop{\rm arg\,max}}
\def\argmin{\mathop{\rm arg\,min}}



\setcounter{section}{0} % starts numbering section 1start_value=[0.498,-0.2874,0.4314,0.5444];

\setcounter{page}{1}



% \usepackage[pdftex]{hyperref}
\begin{document}

\title{Heterogeneity in Firms: \\
A Proxy Variable Approach for Quantile Production Functions
%\footnote{}
}

\author{Justin Doty\thanks{Department of Economics, University of Iowa, S321 Pappajohn Business Building, 21 E Market St, Iowa City, IA 52242. Email: \texttt{justin-doty@uiowa.edu}} and Suyong Song\thanks{Department of Economics and Finance, University of Iowa, W360 Pappajohn Business Building, 21 E Market St, Iowa City, IA 52242. Email: \texttt{suyong-song@uiowa.edu}}
}

\date {\today}
\maketitle


\begin{abstract}
We propose a new approach to estimate firm-level production functions in which output elasticities are heterogeneous across the firm-size distribution. 
This paper extends the proxy variable approach for estimating production functions to the conditional quantiles of firm production. Production function parameters are identified by conditional quantile restrictions and estimated using the implied unconditional sample moment restrictions. We show that this method allows us to capture heterogeneity in output elasticities along the firm-size distribution that would not be estimated in conditional mean models. We provide small-sample evidence in a Monte Carlo study to show that this approach is robust compared to other production function estimators. The method is applied to firm and plant-level manufacturing data from the US, Chile, and Colombia.
\end{abstract}


\textit{Keywords:} Production functions, Heterogeneous elasticity, Nonlinear quantile regression

\textit{JEL Classification:} C14, C36, D24


\pagenumbering{arabic}

\baselineskip25pt

%\singlespacing
\onehalfspacing
%\doublespacing

\section{Introduction}

Production function estimation is an ongoing and historical empirical research topic that links firm's input to output decisions. Identification of the output elasticities and consequently the distribution of firm-level productivity is constrained by endogeneity issues. This is because productivity is unobserved by the econometrician, but observed by the firm when making input decisions. 

A popular approach to address this issue is to introduce a proxy variable such as investment, made popular by \cite{Olley1996} or an intermediate material input using \cite{Levinsohn2003} or \cite{Ackerberg2015}. These proxies are a function of a state variable such as capital and the unobserved productivity components. Under certain assumptions, this demand function is strictly increasing in its scalar unobserved productivity component. Inverting this demand function controls for unobserved productivity and the production function parameters can be estimated with a simple two-stage estimator.

While these methods have been useful in identifying the production function parameters and recovering consistent estimates of total factor productivity (TFP) resulting estimates may be biased if there is additional heterogeneity in production technology across firms. Thus, allowing for heterogeneous coefficients is one possible way to capture these differences. The literature on heterogeneous production functions is small relative to the empirical research using the homogeneous coefficient model, even though many empirical studies have found firm's heterogeneous behavior and decision.\footnote{Some notable examples are \cite*{Kasahara2015}, \cite*{balat}, \cite*{Li2017} and \cite*{mert} to name of few. Also \cite{Gandhi2020} who estimate a nonparametric production function and obtain heterogeneous estimates by construction.} This is because estimating the homogeneous coefficient model by itself is very difficult due to the issue of unobserved productivity. 

In our approach we allow firm heterogeneity in production technology beyond Hick's neutral productivity shock to be driven by the rank of the unobserved production shock, $\eta_{it}$.  We simultaneously extend the proxy variable approach to this framework in order to control for the part of production unobservables that are correlated with inputs. Since applying the quantile regression requires non-smooth criterion function, it is not straightforward to estimate the production functions by allowing for endogenous inputs and their heterogeneous coefficients. We are not aware of any published paper which takes into account for the endogeneity issue of production functions in the conventional quantile regression framework. We fill the gap in this paper by proposing an easy-to-implement estimator.

We show through simulation, that our proposed two-step estimator performs relatively well to the most current control function approach of \cite{Levinsohn2003} and is successful in capturing heterogeneous output elasticities along the conditional distribution of firm's output. In our empirical application, we consider several popular firm and plant-level manufacturing datasets and compare our estimator to control function approaches. We show that heterogeneity in these estimates implies differences in other features of the production function, such as capital intensity and TFP growth over time. 

The rest of the paper is organized as follows. Section \ref{litreview} reviews prior approaches for production function estimation and the literature on panel data quantile regression. Section \ref{ourmodel} introduces the econometric model and the proposed estimator. Section \ref{montecarlo} presents finite-sample behaviors of the estimator via Monte Carlo experiments and Section \ref{application} applies this estimator to US, Chilean, and Colombian manufacturing datasets. Section \ref{conclusion} concludes with directions for future research.

\section{Literature Review} \label{litreview}
\subsection{Production Function Estimation}

We briefly review the LP (2003) procedure for estimating a \textit{value-added} production function (in logs) \footnote{We consider a value-added production function here to be consistent with the model we introduce in Section \ref{ourmodel} for reasons which we will discuss in the corresponding section}\footnote{We drop the constant $\beta_{0}$ since it is not separately identified from $\omega_{it}$ without a location normalization}.

\begin{equation}
y_{it}=\beta_{k}k_{it}+\beta_{l}l_{it}+\omega_{it}+\eta_{it}.
\end{equation}
where $y_{it}$ denotes value-added output, $l_{it}$ denotes labor input for firm $i$ at time $t$, $k_{it}$ denotes capital input, $\omega_{it}$ is unobserved productivity and $\eta_{it}$ denotes an iid shock to production.

To control for the correlation between $\omega_{it}$ and inputs $k_{it}$ and $l_{it}$. LP introduce an intermediate input demand defined as \footnote{In the original paper of \cite{Levinsohn2003} they consider multiple intermediate inputs such as energy, fuels, and materials as potential proxies. We focus on material inputs as the proxy.}
\begin{equation}
m_{it}=m_{t}(k_{it}, \omega_{it})
\end{equation}
where the function $f$ is strictly increasing in $\omega_{it}$ for all $k_{it}$. Productivity can then be expressed as
\begin{equation}
\omega_{it}=m_{t}^{-1}(k_{it}, m_{it}).
\end{equation}
Substituting into the production function
\begin{equation}
y_{it}=\beta_{k}k_{it}+\beta_{l}l_{it}+m^{-1}_{t}(k_{it}, m_{it})+\eta_{it}=\beta_{l}l_{it}+\Phi(k_{it}, m_{it})+\eta_{it}
\end{equation}
An estimate for $\beta_{l}$ and $\Phi_{t}(k_{it}, m_{it})$ can be obtained by the following first stage moment restriction
\begin{equation}
\mathbb{E}[y_{it}-\beta_{l}l_{it}-\Phi_{t}(k_{it}, m_{it})|\mathcal{I}_{it}]=0
\end{equation}
where $\mathcal{I}_{it}$ denotes the firm's information at time $t$. A linear approximation can be used, in which case estimates can be obtained from a simple linear regression.

A second stage moment restriction identifies the coefficient on capital. Assume that productivity follows an auto-regressive process
\begin{equation}
\omega_{it}=\mathbb{E}[\omega_{it}|\omega_{it-1}]+\xi_{it}=g(\omega_{it-1})+\xi_{it}
\end{equation}
where $\xi_{it}$ denotes an innovation to productivity and satisfies $\mathbb{E}[\xi_{it}|\mathcal{I}_{it-1}]=0$.

Then, the production function parameters can be estimated from the moment restrictions
\begin{equation}
\begin{split}
\mathbb{E}[\xi_{it}+\eta_{it}|\mathcal{I}_{it-1}]&=\\
\mathbb{E}[&\tilde{y}_{it}-\beta_{k}k_{it}\\
&-g(\hat{\Phi}_{t-1}(k_{it-1}, m_{it-1})-\beta_{k}k_{it-1})|\mathcal{I}_{it-1}]=0,
\end{split}
\end{equation}
where $\tilde{y}_{it}=y_{it}-\hat{\beta}_{l}l_{it}$ and $\hat{\Phi}$ denotes estimates from the first stage. LP proceed by using instruments from $\mathcal{I}_{it-1}$ and minimize a Generalized Method of Moments (GMM) criterion function. Standard errors are obtained using a bootstrap procedure since the two-step nature of this estimators complicates asymptotic inference.


\subsection{Production Functions and Quantile Regression}


Connecting variation in the random error, $\eta_{it}$, to differences in a firm's final output decisions is not straightforward in the standard production function model. We briefly review a subfield of production function estimation that facilitates a more natural interpretation; production frontier models. We discuss limitations of these applications and return to our interpretation in Section \ref{ourmodel}.

A (stochastic) frontier (SFA) model of production proposed by \cite{Aigner1977} introduces statistical error into a frontier model. Frontier models assume firms firms deviate from an optimal frontier of production. The SFA model is typically written as
\begin{equation}
y_{i}=f(x_{i}, \beta)+\varepsilon_{i},
\end{equation}
where $\varepsilon_{i}=\eta_{i}-u_{i}$, $x_{i}$ are inputs to production and $\beta$ are the parameters. The error term $\eta_{i}$ denotes the statistical noise in the model such as measurement error and $u_{it}$ represents one-sided deviations from the production frontier. Estimates of $\beta$ are typically obtained using maximum likelihood which requires strong distributional assumptions on the error terms. Estimation of the efficient frontier is then a conditional mean estimator rather than a maximal value estimator as noted by \cite{Bernini2004}. They suggest quantile regression could then be used to estimate the highest percentiles of the conditional output distribution as it relates to the stochastic frontier, however, a theoretical difficulty is then choosing which quantile corresponds to the frontier. A more detailed derivation of a quantile representation of the frontier was introduced by \cite{Aragon2005} in a nonparametric model which requires inversion of a conditional empirical CDF. Since the purpose of this paper is not to compare the advantages and disadvantages of production frontier models and ours we leave this discussion for future studies and acknowledge the theoretical challenges of quantile frontier models. 

There are two main challenges of implementing a quantile regression framework to the standard production function model. Firstly, as we alluded to earlier in this section, if we maintain a structural interpretation of firm production, reduced-form linear quantile regression models are likely not sufficient in linking a firm's output choice as a function of the error term $\eta_{it}$ as we elaborate in the next section. Secondly, addressing the endogeneity of $\omega_{it}$ using traditional panel data methods have challenges specific towards the production function literature and quantile models.

Regarding the second point, quantile panel data models allow for flexible interactions between unobserved heterogeneity and the quantiles of the conditional response function. Some well known approaches assume a time-invariant fixed effect such as \cite{Koenker2004}, \cite{Lamarche2010}, \cite{Canay2011} which acts as a pure location shifter of the conditional quantile function. This approach may have two main disadvantages. First, assuming the unobservable is time-invariant is restrictive and \cite{Griliches1986} has shown to leads to low estimates of $\beta_{k}$. Secondly, the fixed effects of these models are incidental parameters so as the sample size grows, so does the number of parameters that need to be estimated which makes it computationally costly. An alternative to fixed effect estimation is to model the unobserved heterogeneity as a projection onto the observables plus a disturbance in the spirit of \cite{Chamberlain1984}. \cite{Abrevaya2008} adopt this approach with a linear data generating process for birth outcomes and linking it to its quantile function to estimate the effect of birth inputs over the birth-weight distribution. This approach is further developed by \cite{Bache2012}. One downside of this approach is that it is difficult to describe the behavior of the conditional quantile function as it depends on the joint distribution of unobservables in the response function and the random effect.

Another alternative is to make use of valid instruments if they are available. The conventional argument for using input prices $p^{k}_{it}$ and $p^{l}_{it}$ as instruments is that they must be uncorrelated with the error term $\omega_{it}+\eta_{it}$ and correlated with input choices for capital and labor. Then one could use two-stage least squares to obtain consistent estimates of $\beta_{k}$ and $\beta_{l}$. This idea can be extended to quantile-IV models such as \cite{Chernozhukov2005}. In their identification arguments, one would need to strengthen assumptions to conditional independence as well as monotonicity of a quantile structural function (QSF) in $U_{it}=\omega_{it}+\eta_{it}$. Then if one writes the QSF for the production function as $y_{it}=Q(k_{it}, l_{it}, U_{it})$ where $\tau\in (0,1]$ denotes the quantile index, the model is identified from a quantile type moment restriction
\begin{equation}
P[y_{it}\leq Q(k_{it}, l_{it}, \tau)|k_{it}, l_{it}, p^{k}_{it}, p^{l}_{it}]=\tau
\end{equation}
while this identification argument is used in our model, we do not use the estimation procedure for reasons explained in the next section. One of these reasons are that input prices may not have enough variation across firms and exogeneity can be violated if they capture input quality differences as argued by \cite{Griliches1986}.


\section{A Random Coefficient Production Function} \label{ourmodel}
We specify a \textit{value-added} production function as a random coefficient model:
\begin{equation} \label{pfrc}
    y_{it}=\beta_{k}(\eta_{it})k_{it}+\beta_{l}(\eta_{it})l_{it}+\omega_{it}
\end{equation}
A value-added specification in equation \eqref{pfrc} is non-trivial. Value-added production functions are common in the empirical literature, however the objects recovered from a value-added model such as the output elasticities and TFP can only be mapped to its gross-output counterpart under specific structural production functions. Since the production shock enters \eqref{pfrc} non-separably, it is difficult to recover gross-output objects from value-added due to the presence of ex-post shocks. Therefore, in our empirical application we interpret the elasticities and TFP with some caution.\\

 One advantage of the value-added approach is that the rank of $\eta_{it}$ can now be interpreted as the rank of firm-size as measured by value-added which accounts for firm size from the value of output created through capital and labor. There may be other reasons to measure firm-size by other measures such as gross-output (sales) or employment which is sometimes refined as employee weighted average of number of employees \citep{Kumar1999}. The value-added approach also avoids the non-identification results of \cite{Gandhi2020}. We leave the connection between this value-added production function and its possibly underlying gross-output production function as future work. \\

The variables in equation \eqref{pfrc} have the same interpretation as the ones we introduced in the LP model. The only difference here is that we allow the output elasticities to be functionally dependent on the production shock $\eta_{it}$ while productivity still maintains its additive separability. \footnote{More specifically, productivity is only a location shifter of the conditional output distribution. We cannot allow $\omega_{it}=\omega_{it}(\eta_{it})$ since this would violate the scalar unobservability assumption of our proxy variable}

A special case of \eqref{pfrc} is the location scale model,

\begin{equation} \label{locationscale}
    y_{it}=\beta_{k}k_{it}+\beta_{l}l_{it}+\omega_{it}+(\mu_{k}k_{it}+\mu_{l}l_{it})\eta_{it}
\end{equation}
Which implies that the $\tau$th conditional quantile of $y_{it}$ is given by

\begin{equation}
Q_{y_{it}}(\tau|\mathcal{I}_{it})=\beta_{k}k_{it}+\beta_{l}l_{it}+\omega_{it}+(\mu_{k}k_{it}+\mu_{l}l_{it})F^{-1}(\tau)
\end{equation}
where $F^{-1}(\tau)$ is the quantile function of production shocks $\eta_{it}$.

The formulation of \eqref{locationscale} is not new to the production function literature. The assumption that input choices can impact firm's production beyond the conditional mean has important consequences for firm's attitude towards production risk. A volume of literature that originated in the late 1970's challenged the standard stochastic specifications of production functions \citep{Just1978,Just1979} by considering a specification that allowed firm's inputs to both increase or decrease the marginal variability of final output. The most common application of those models are in the agricultural industry where the variance on the yield of harvested crops could be increased by adverse weather or decreased by pesticide usage. Since manufacturing businesses tend to operate in a more controlled environment, risk is less prevalent in these industries so the conditional variance of $\eta_{it}$ may be smaller. A general quantile model such as the one specified in \eqref{pfrc} can be seen as an extension of the higher-order moment estimation of risk initiated by \cite{Antle1983}. However, it can also be seen purely as an econometric specification issue as we are unaware of any tests that could distinguish between higher order moment production risk and misspecification. We choose the latter interpretation for our model. 

We note that under quantile preferences a firm who maximizes the $\tau$ level of utility of profits could explain heterogeneity in the output distribution. Unlike risk-neutral firms, firms could have a utility function that is represented by preferences of the firm manager(s) who decides the optimal expenditure on inputs. Different managers may have different preferences for risk. Quantile utility maximization is not a new concept. A short list of papers have considered quantile utility maximization such as \cite{Manski1988}, \cite{ROSTEK2009}, \cite{Chambers2007}, and \cite{Bhattacharya2009}. Dynamic input choices such as investment are much more difficult to solve using the quantile utility framework and the reader can refer to \cite{Castro2017} for a treatment of dynamic quantile utility models. As far as we know, the quantile utility framework has not been applied to firm decision problems and a more thorough treatment of such is outside the scope of this paper.

\subsection{Identification}
\subsubsection{Production Function in \cite{Levinsohn2003}}
Returning to our misspecification interpretation in Equation \eqref{pfrc}, we follow LP in the usual set of assumptions on timing of input choices and scalar unobservability.

\begin{assump} \label{qpfassume}
~
\begin{enumerate}[label=(\alph*)]
	\item The production function $y_{it}=f_{t}(k_{it}, l_{it}, \omega_{it}, \eta_{it})$ is strictly increasing in $\eta_{it}$
	\item The firm's information set at time $t$ includes current and past productivity shocks $\{\omega_{it}\}_{t=0}^{t}$, but does not include past productivity shocks $\{\omega_{it}\}_{t=t+1}^{\infty}$. $\eta_{it}$ is independent of $\mathcal{I}_{it}$
	\item Firm's productivity shocks evolve according to a first-order Markov process
	\begin{equation}
	\omega_{it}=g(\omega_{it-1})+\xi_{it}
	\end{equation}
	where the iid productivity innovations $\xi_{it}$ satisfy $\mathbbm{E}[\xi_{it}|\mathcal{I}_{it-1}]=0$
	\item Firms accumulate capital according to
	\begin{equation}
	    K_{it}=\kappa_{t}(I_{it-1}, K_{it-1}).
	\end{equation}
	where $K_{it-1}$ and $I_{it-1}$ denote previous period capital and investment
	\item Firm's intermediate input demand function is given by $m_{it}=m_{t}(k_{it}, \omega_{it})$
	\item The intermediate input demand function $m_{t}(k_{it}, \omega_{it})$ is strictly increasing in $\omega_{it}$
\end{enumerate}
\end{assump}

Given these Assumption \eqref{qpfassume}(e, f), we invert intermediate input demand $\omega_{it}=m^{-1}(k_{it}, m_{it})$ and substitute into the production function. We treat $m_{t}^{-1}$ as a nonparametric function $(k_{it}, m_{it})$. We then have:
\begin{equation} \label{qpf1st}
y_{it}=\beta_{k}(\eta_{it})k_{it}+\beta_{l}(\eta_{it})l_{it}+m_{t}^{-1}(k_{it}, m_{it})=\beta_{l}(\eta_{it})l_{it}+\Phi(k_{it}, m_{it}, \eta_{it})
\end{equation}

Using Assumption \eqref{qpfassume}(a, b) we have the following identification condition for the first stage:
\begin{equation} \label{1ststageident}
	P\big(y_{it}\leq \beta_{l}(\tau)l_{it}+\Phi(k_{it}, m_{it}; \tau)\big|\mathcal{I}_{it})=\tau
\end{equation}

The equation in \eqref{qpf1st} is a semiparametric partially linear quantile regression model which can be consistently estimated using approaches proposed by \cite{Lee2003}, \cite{KOENKER1994}, or \cite{Chen2009}. We can then plug these estimates back into the production function and apply Assumption \eqref{qpfassume}(c) to obtain:
\begin{equation} \label{qpf2nd}
y_{it}=\beta_{k}(\eta_{it})k_{it}+\hat{\beta}_{l}(\tau)l_{it}+g(\hat{\Phi}(k_{it-1}, m_{it-1}; \tau)-\beta_{k}(\eta_{it})k_{it-1})+\xi_{it}
\end{equation}

The main challenge of the identification result in the second stage is that it is not true in general that
\begin{equation} \label{2ndstageidentification}
P\big(y_{it}\leq \beta_{k}(\tau)k_{it}+\hat{\beta}_{l}(\tau)l_{it}+g(\hat{\Phi}(k_{it-1}, m_{it-1}; \tau)-\beta_{k}(\tau)k_{it-1})+\xi_{it}|\mathcal{I}_{it-1}\big)=\tau
\end{equation}
The lack of identification in using the above equation is related to the identification issues of quantile panel data models using correlated random effects. For example, \cite{Canay2011} notes that the conditional behavior of \eqref{2ndstageidentification} depends on the joint distribution of $\eta_{it}$ and $\xi_{it}$ which makes identification of $(g, \beta_{k}(\tau))$ in the second stage problematic. Identification issues related to quantile panel data models using conditional quantile restrictions are studied by \cite{Rosen2012} who develops conditions for both set and point identification. \cite{Cai2018} note that an equation like \eqref{qpf2nd} can be interpreted as measurement error in the dependent variable of a quantile regression model where $\xi_{it}$ is the measurement error in $y_{it}$. This type of model is studied by \cite{Hausman2019} who use a sieve MLE approach for estimating the density of the measurement error. Both aforementioned papers require varying degrees of distributional assumptions on the error term which we would like to avoid in our model. An alternative would be to use the entropic integration method of \cite{2014a} and integrate out $\xi_{it}$ via simulation. However, this approach would introduce additional nuisance parameters that would need to be estimated. 

We can avoid distributional assumptions and nuisance parameters by framing the identification condition in the $\xi_{it}$ component, similar to \cite{Ackerberg2015} by concentrating out the constant $\beta_{0}(\tau)$ and $g$. For a hypothetical guess of $\beta_{k}(\tau)$, say  $\tilde{\beta}_{k}(\tau)$ we can write for a fixed $\tau\in (0,1]$
\begin{equation}
\beta_{0}(\tau)+\omega_{it}=y_{it}-\hat{\beta}_{l}(\tau)l_{it}-\tilde{\beta}_{k}(\tau)k_{it}=\hat{\Phi}(k_{it}, m_{it}; \tau)-\tilde{\beta}_{k}(\tau)k_{it}
\end{equation}
We can rewrite the AR(1) productivity process as
\begin{equation}
\hat{\Phi}(k_{it}, m_{it}; \tau)-\tilde{\beta_{k}}(\tau)k_{it}=\beta_{0}(\tau)+g(\hat{\Phi}(k_{it-1}, m_{it-1}; \tau)-\tilde{\beta_{k}}(\tau)k_{it-1})+\xi_{it}
\end{equation}
and note that the implied residuals satisfy
\begin{equation} \label{2ndxi}
\mathbbm{E}[\xi_{it}(\tilde{\beta}_{k}(\tau))|\mathcal{I}_{it-1}]=0
\end{equation}
which can be estimated by standard GMM procedures for a fixed $\tau\in (0,1]$\\

This estimator is then a simple extension of the control function approach where the first stage parameters are estimated using quantile regression techniques. The location-shift assumption on the productivity process allows us to identify and estimate the parameters in the second stage while concentrating out additional parameters. Some interesting extensions could include additional heterogeneity in the productivity process such as a location-scale model for productivity which could be estimated using \cite{He1997} or a random-coefficient model where second stage identification would rely on a conditional quantile restriction and estimated using \cite{Kaplan2016}.

\subsubsection{Production Function in \cite{Ackerberg2015}}
In the \cite{Ackerberg2015} setting, the intermediate input demand $m_{it}=m_{t}(k_{it}, l_{it}, \omega_{it})$ is conditional on the labor input. This allows a more flexible timing assumption on when labor is chosen by the firm relative to the other inputs. Labor can have dynamic implications and be partially or fully realized before productivity $\omega_{it}$. In this setting, the labor elasticity $\beta_{l}$ cannot be identified in the first stage as in the LP approach. The first stage equation is then:
\begin{equation}\label{acf1}
y_{it}=\beta_{k}(\eta_{it})k_{it}+\beta_{l}(\eta_{it})l_{it}+m_{t}^{-1}(k_{it}, l_{it}, m_{it})=\Phi(k_{it}, l_{it}, m_{it}, \eta_{it}),
\end{equation}
where we have used monotonicity of the intermediate input demand function in $\omega_{it}$ to control for unobserved productivity. The nonparametric function $\Phi(\cdot;\tau)$ can be identified using Assumption \eqref{qpfassume} (a) and (b)
\begin{equation} \label{acfqpf1}
P\big(y_{it}\leq \Phi(k_{it}, l_{it}, m_{it}; \tau)\big|\mathcal{I}_{it})=\tau
\end{equation}
which suggests that the functional $\Phi(\cdot, \tau)$ can be estimated by nonparametric quantile methods such local linear or polynomial regression \citep{Chaudhuri1991,Chaudhuri1991a}, smoothing splines \citep{KOENKER1994}, or more general sieve based estimation \citep{2012a}.\\
As before, we concentrate out the constant $\beta_{0}(\tau)$ and $g$. For a hypothetical guess of $(\beta_{l}(\tau), \beta_{k}(\tau))$ we can write
\begin{equation}
\beta_{0}(\tau)+\omega_{it}=y_{it}-\tilde{\beta}_{l}(\tau)l_{it}-\tilde{\beta}_{k}(\tau)k_{it}=\hat{\Phi}(k_{it}, l_{it}, m_{it}; \tau)-\tilde{\beta}_{k}(\tau)k_{it}-\tilde{\beta}_{l}(\tau)l_{it}
\end{equation}
We can rewrite the AR(1) productivity process as
\begin{equation}
\begin{split}
\hat{\Phi}(k_{it}, l_{it}, m_{it}; \tau)&-\tilde{\beta}_{k}(\tau)k_{it}-\tilde{\beta}_{l}(\tau)l_{it}\\
&=\beta_{0}(\tau)+g(\hat{\Phi}(k_{it-1}, l_{it-1}, m_{it-1}; \tau)-\tilde{\beta}_{k}(\tau)k_{it-1}-\tilde{\beta}_{l}(\tau)l_{it-1})+\xi_{it}
\end{split}
\end{equation}
and note that the implied residuals satisfy
\begin{equation}
\mathbbm{E}[\xi_{it}(\tilde{\beta}_{k}(\tau), \tilde{\beta}_{l}(\tau))|\mathcal{I}_{it-1}]=0
\end{equation}
which can be estimated by standard GMM procedures for a fixed $\tau\in (0,1]$

\subsection{Estimation}
We discuss how to estimate the LP production function in two stages. 
\subsubsection*{First Stage}
Recall, in the first stage we have the identification condition
\begin{equation} 
	P\big(y_{it}\leq \beta_{l}(\tau)l_{it}+\Phi(k_{it}, m_{it}; \tau)\big|\mathcal{I}_{it})=\tau
\end{equation}
which yields
\begin{equation} 
	\mathbbm{E}\big[\mathbbm{1}\{y_{it}\leq \beta_{l}(\tau)l_{it}+\Phi(k_{it}, m_{it}; \tau)\}-\tau\big|\mathcal{I}_{it}]=0
\end{equation}
Similar to \cite{Olley1996}, $\Phi(\cdot;\tau)$ can be approximated by a flexible polynomial so that estimates $\hat{\beta_{l}}(\tau)$ and $\hat{\Phi}(\cdot;\tau)$ can be obtained from a polynomial quantile regression. A more complete model of $\Phi(\cdot;\tau)$ can be obtained using a finite-dimensional sieve and estimated using a minimum distance criterion function. We briefly introduce this approach.\\

To fix notation, let $x_{it}=(k_{it}, m_{it})$ denote the variables in the nonparametric function, $\Phi$. Let $\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi(x_{it}))=\mathbbm{1}\{y_{it}-\beta_{l}(\tau)l_{it}-\Phi(x_{it})\leq 0\}-\tau$. Rephrasing our first stage identification condition as 
\begin{equation} \label{residual}
\mathbbm{E}[\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi(x_{it}))|\mathcal{I}_{it}]=0
\end{equation}
we can see that this resembles the semiparametric moment conditions studied by \cite{Chen2009} and \cite{Ai2012} where the residual function is non-differentiable in $(\beta_{l}, \Phi)$ due to the indicator function. However, one difference between our model and theirs is that there is no endogeneity in the first stage which simplifies estimation. Let $\alpha=(\beta_{l}, \Phi)$. The first stage estimates can be found from the following minimization problem
\begin{equation}
(\hat{\beta}_{l}, \hat{\Phi})=\underset{\alpha\in(\Theta\times \mathcal{H}_{k(n)})}{\operatorname{argmin}}\sum_{i=1}^{N}\sum_{t=1}^{T}\hat{\mathbbm{E}}[\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi)|\mathcal{I}_{it}]^{'}\hat{\Sigma}_{1}^{-1}\hat{\mathbbm{E}}[\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi)|\mathcal{I}_{it}]
\end{equation}
where $\Theta\subset \mathbbm{R}$ with $\beta_{l}\in\Theta$ and $\{\mathcal{H}_{k(n)}: k(n)=1,2,\dots\}$ is a sequence of approximating finite dimensional linear sieve spaces which becomes dense as $k(n)\rightarrow \infty$. In practice one could use a tensor-product linear sieve basis function such as B-splines or polynomials. $\hat{\mathbbm{E}}[\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi)|\mathcal{I}_{it}]$ and $\hat{\Sigma}_{1}$ are nonparametric estimators of $\mathbbm{E}[\Lambda_{1}(y_{it}, l_{it}; \beta_{l}, \Phi)|\mathcal{I}_{it}]$ and $\Sigma_{1}$ which can be obtained using series LS estimator and $\hat{\Sigma}_{1}=\tau(1-\tau)$. In our simulation study and empirical application we use a 3rd order polynomial with interactions and estimate the first stage parameters using simple weighted linear quantile regression, which we justify in the next section.

\subsubsection*{Second Stage}
Once estimates of $\beta_{l}(\tau)$ and $\Phi(k_{it}, m_{it}; \tau)$ are obtained, we can estimate the residuals of the productivity innovation shocks for a given $\tilde{\beta}_{k}(\tau)$
\begin{equation}
\hat{\xi}_{it}(\tilde{\beta}_{k}(\tau))&=\hat{\Phi}(k_{it}, m_{it}; \tau)-\tilde{\beta}_{k}(\tau)k_{it}
-g(\hat{\Phi}(k_{it-1}, m_{it-1}; \tau)-\tilde{\beta}_{k}(\tau)k_{it-1}, \rho)
\end{equation}
where we parameterize the process for productivity $g$ by a finite dimensional parameter vector $\rho$.\footnote{We use a third degree polynomial in $\omega_{it-1}$ to estimate $g$ in the empirical application. In practice, one could estimate $g$ nonparametrically, however this complicates the asymptotic results} To simplify notation in the later section we let $\beta=(\beta_{0}, \beta_{k}, \rho)$ and $\hat{\xi}_{it}(\tilde{\beta}_{k}(\tau))=\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))$. so we can rewrite the moment condition in equation \eqref{2ndxi} as
\begin{equation} \label{new2ndstage}
\mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))|\mathcal{I}_{it-1}]=0
\end{equation}
The capital coefficient is identified using the fact that current capital does not respond to innovation shocks in productivity. In practice we include additional instruments $(k_{it-1}, l_{it-1}, m_{it-1})$ so that our model is over-identified and $\beta_{k}(\tau)$ can be estimated using a GMM criterion function so that $\hat{\beta}$ solves 
\begin{equation}
\hat{\beta}=\underset{\beta}{\operatorname{argmin}}\,\hat{\mathbbm{E}}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))]^{'}\hat{\Sigma}_{2}\hat{\mathbbm{E}}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))]
\end{equation}

where $\hat{\mathbbm{E}}[\cdot]$ are the sample unconditional moments corresponding to \eqref{new2ndstage} and $\hat{\Sigma}_{2}$ may be an arbitrary weighting matrix. We discuss how to efficiently choose the weighting matrix in this two-step approach using \cite{Ackerberg2014} in the next section.

\subsection{Asymptotics}
We divide the discussion of asymptotics in two parts. In the first part, we show how the coefficients for the variable inputs identified in the first stage can be efficiently estimated using \cite{Ai2012}. In the second part, we show how the capital coefficient can be efficiently estimated using the appropriate weighting matrix as shown in \cite{Ackerberg2014}.
\subsubsection*{First Stage}
The main difficulty in establishing asymptotic normality for the labor estimate in the first stage is the non-smoothness of the residual function in equation \eqref{residual}. \cite{Chen2009} extend the results of \cite{Ai2003} to show that the estimate of the parametric part of their model is not only asymptotically normal, but also establish its semiparametric efficiency bound. In the model without endogeneity, they show that their estimator reaches the same efficiency bound as \cite{Lee2003}. Readers can refer to Section 5 of \cite{Chen2009}, in particular, Remark 5.1 illustrates how to weaken their assumptions in the case of exogeneity. Let $u_{it}=y_{it}-\beta_{l}l_{it}-\Phi(x_{it})$. Using Condition 5.6 and 5.7 in \cite{Chen2009}
\begin{equation}
\sqrt{n}(\hat{\beta}_{l}-\beta_{l})\rightarrow N(0, V_{1}^{-1})
\end{equation}
where
\begin{equation}
V_{1}=\tau(1-\tau)\Bigg\{\mathbbm{E}[f^{2}_{U|L,X}(0)l^{2}_{it}]-\mathbbm{E}\Bigg[\frac{\mathbbm{E}\big[f^{2}_{U|L,X}(0)l_{it}|X\big]^{2}}{\mathbbm{E}\big[f^{2}_{U|L,X}(0)|X\big]}\Bigg]\Bigg\}^{-1}
\end{equation}
A simple consistent estimator for the asymptotic variance can be given by
\begin{equation}
\hat{V}_{1}=\tau(1-\tau)\Bigg\{\frac{1}{NT}\sum_{i=1}^{N}\sum_{t=1}^{T}\Bigg[\hat{f}^{2}_{U|L,X}(0)l_{it}^{2}-\frac{\hat{\mathbbm{E}}\big[f^{2}_{U|L,X}(0)l_{it}|X\big]^{2}}{\hat{\mathbbm{E}}\big[f^{2}_{U|L,X}(0)|X\big]}\Bigg\}\Bigg]\Bigg\}^{-1}
\end{equation}
where $\hat{f}_{U|L,X}(0)$ and $\hat{\mathbbm{E}}[\cdot|X]$ are consistent nonparametric estimators of $f_{U|L,X}(0)$ and $\mathbbm{E}[\cdot|X]$. An alternative to plugging in these into the estimate of the asymptotic variance, is to use a weighted bootstrap procedure. \cite{Chen2009} show that this algorithm produces consistent estimates the asymptotic distribution of $\beta_{l}$ as long as one chooses an i.i.d sample of positive weights denoted by $w_{it}$ which satisfy $\mathbbm{E}[w_{it}]=1$ and $Var[w_{it}]<\infty$ and is independent from the data. In practice we draw weights from a standard exponential distribution for each iteration of the bootstrap procedure and use these to compute a weighted quantile regression estimator of $\beta_{l}$ and $\Phi$.

\subsubsection*{Second Stage}
Asymptotic normality of two-stage GMM estimators is well-established in the literature. The second stage estimates satisfy
\begin{equation}
\sqrt{n}(\hat{\beta}-\beta)\overset{d}{\operatorname{\rightarrow}}N(0,V_{2})
\end{equation}
where 
\begin{equation}
V_{2}=(G_{2}^{'}\Sigma_{2}G_{2})^{-1}(G_{2}^{'}\Sigma_{2}V_{\Lambda 2}\Sigma_{2}G_{2})(G_{2}^{'}\Sigma_{2}G_{2})^{-1}
\end{equation}
Here, $G_{2}=\frac{\partial \mathbbm{E}(\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))}{\partial \beta}, V_{\Lambda 2}=Var(\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it})))$ and $\Sigma_{2}$ is the weighting matrix. The two-step GMM estimator of $\beta$ is not efficient since the information sets used in the first stage and the second stage are not simultaneously considered. In order to adjust for the variance in estimating the first stage parameters $\beta_{l}$ and $\Phi$, we show how \cite{Ackerberg2014} can be applied to choosing an optimal weighting matrix that reflects the noise from the first stage estimates and provide the semi-parametric efficiency bound.\\

The intuition of the \cite{Ackerberg2014} approach is that under certain conditions, the original unconditional moments $\mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi(x_{it}))]$ can be orthogonalized with respect to the moment condition in equation \eqref{residual}. When the first step is exactly identified from a semiparametric partially linear quantile restriction, this new moment condition is written as:\footnote{Although the results of \cite{Chen2009} and \cite{Ai2012} do not require the first step to be exactly identified, we require it in order to derive the semiparametric efficiency bound for the second step estimates}
\begin{equation}\label{orthomoment}
\begin{split}
\tilde{\Lambda}_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)=&\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)+\sum_{t=1}^{T}\Bigg[\Bigg(\frac{\partial \mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)|\mathcal{I}_{it-1}]}{\partial l_{it}}\\
+&\frac{\partial \mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)|\mathcal{I}_{t-1}]}{\partial \Phi^{'}_{j}}\Bigg)\times \frac{\tau-\mathbbm{1}\{y_{it}\leq\beta_{l}l_{it}-\Phi_{t}(x_{it})\}}{f_{U|L,X}(0)}\Bigg]
\end{split}
\end{equation}
\cite{Ackerberg2014} show that the semiparametric efficiency bound for $\beta$ can be written as the inverse of
\begin{equation}
\tilde{V}_{2}=\Bigg(\frac{\partial\mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)]}{\partial\beta}\Bigg)^{'}Var(\tilde{\Lambda}_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi))^{-1}\Bigg(\frac{\partial\mathbbm{E}[\Lambda_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi)]}{\partial\beta}\Bigg)
\end{equation}
so that this bound can be achieved by choosing a weighting matrix $\Sigma_{2}=Var(\tilde{\Lambda}_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi))^{-1}$ which can be consistently estimated by plugging in estimates $\hat{\beta}_{l}$, $\hat{\Phi}$, and $\hat{f}_{U|L,X}(0)$ from the first stage.

In practice, it is much easier to compute a numerically equivalent estimate of $Var(\tilde{\Lambda}_{2}(y_{it}, l_{it}, \beta_{l}, \beta, \Phi))^{-1}$ as shown by \cite{Ackerberg2012} which is outlined by \cite{Ackerberg2014} in Section 3.3 of their paper. 

\section{Monte Carlo Experiments} \label{montecarlo}
We use a location-scale version of \cite{Levinsohn2003} and replicate \cite{Ackerberg2015} simulations sampling 1000 datasets consisting of 1000 firms. We simulate optimal input choices for 100 time periods, using the last 10 periods for estimation. 

\begin{equation}
y_{it}=\beta_{0}+\beta_{k}k_{it}+\beta_{l}l_{it}+\omega_{it}+(\gamma_{0}+\gamma_{k}k_{it}+\gamma_{l}l_{it})\eta_{it}
\end{equation}
with $\beta_{0}=0, \beta_{k}=0.4$ and $\beta_{l}=0.6$. The location scale parameters are set as $\gamma_{0}=0, \gamma_{k}=0.7$ and $\gamma_{l}=-0.6$ For each simulation we simulate two DGPs with $\eta_{it}\sim N(0,0.1)$ and $\eta_{it}\sim Laplace(0,0.1)$.

To produce consistent estimates of the labor coefficient in the first stage, we do not allow for any wage variation across firms and labor is chosen at time $t$ with perfect information about $\omega_{it}$. However, we add optimization error in labor. An AR(1) process is specified for productivity $\omega_{it}=\rho\omega_{it-1}+\xi_{it}$ where $\rho=0.7$. The variance of $\xi_{it}$ and initial value $\omega_{i0}$ is set so that the standard deviation of $\omega_{it}$ is constant over time and equal to $0.3$

We compare the LP estimation procedure with our ``QLP'' two-step procedure under the two different sets of experiments specified earlier. We estimate the model for $\tau\in\{0.1, 0.15, \dots, 0.85, 0.9\}$ and use current period capital, $k_{it}$ as our instrument so that our model is exactly identified. For the weighting matrix, we use an estimate of the variance covariance matrix of the sample moments. We use a continuously updated GMM procedure such that estimates of $\beta_{k}(\tau)$ in the second stage are estimated simultaneously with the weighting matrix. We initialize the algorithm at the true value of $\beta_{k}(\tau)$ however we find that the estimation is robust to reasonable initial values.

We focus on whether our estimate can capture heterogeneity in the output distribution reasonably well compared to the mean estimates from the LP approach. Previous papers such as \cite{Olley1996} and \cite{Levinsohn2003} already show that the control function approach controls for endogeneity bias from unobserved productivity and perform specification tests for the set of possible control functions such as investment, material inputs, fuels, and energy. 

Figure \ref{fig:simest} graphs the estimated coefficients for QLP and LP. The black line denotes the QLP estimator and its corresponding $90\%$ confidence interval is the gray shaded area. The solid red line denotes the LP estimator and the dotted red lines are its corresponding $90\%$ confidence interval. Capital coefficients are the first column of the graph and labor coefficients are the second column. The first row corresponds to DGP 1 with $\eta_{it}\sim N(0,0.1)$ and the second row corresponds to DGP 2 with $\eta_{it}\sim Laplace(0,0.1)$. The estimator does reasonable well at capturing heterogeneity outside of the conditional mean estimate for both capital and labor. Not surprisingly, the confidence intervals for capital are wider than the interval for labor due to nature of the multi-step procedure. \ref{fig:MSE}  shows that these estimators perform well in finite sample. The MSE for both estimators is plotted over $\tau\in\{0.1, 0.15, \dots, 0.85, 0.9\}$ with the black line denoting the QLP estimates and the dotted red line denoting the LP estimates.

\begin{figure}[ht] 
\centering
\caption{QLP estimated coefficients of  $\beta_{k}(\tau)$ and $\beta_{l}(\tau)$. Dotted line is LP estimator}
\label{fig:simest}
\includegraphics[width=13cm, height=11cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Monte_Carlo/LP_Coefficient_Plot.png}
\label{LP_coefficient_plot}
\end{figure}


\begin{figure}[ht]
\centering
\caption{Simulated precision of  QLP estimators of $\beta_{k}(\tau)$ and $\beta_{l}(\tau)$s. Dotted line is LP estimator.}
\includegraphics[width=13cm, height=11cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Monte_Carlo/LP_MSE_Plot.png}
\label{fig:MSE}
\end{figure}

\newpage
\section{Application} \label{application}
We apply our estimator to popular firm and plant level manufacturing datasets from the US, Chile, and Colombia to examine heterogeneity in the output distribution \footnote{We thank Mert Demirer for providing the datasets from Chile and Colombia}. For each country we examine estimates across different manufacturing industries as well as how these estimates have changed over time and the implications for heterogeneity in productivity across small and large firms/plants. We use the QLP estimator presented in this paper and compare it to the LP estimates. We also compare our estimates to the quantile regression estimates without controlling for productivity. We estimate the labor coefficient using a partially regression with a 3rd degree polynomial with interactions in capital and materials. To estimate capital, we use the CUE GMM criterion function mentioned earlier with instruments $k_{it}, k_{it-1}, l_{it-1}$ and $m_{it-1}$. We initialize the starting values for the non-linear search using quantile regression estimates of $\beta_{k}(\tau)$. We use bootstrap to estimate standard errors with the number of iterations set to $500$. In the first stage we use a weighted bootstrap with weights drawn from a standard exponential distribution re-sampled at each iteration. In the second stage we use a nonparametric bootstrap and recenter sample moments in each iteration.

\subsection{US Compustat}
The source for the US manufacturing data is from Compustat which covers publicly traded firms and contains data from their financial statements. We collect a sample between 1961 and 2010 on sales, capital expenditures, number of workers, and other expenses to construct measures of output, capital, labor, and material inputs using 3-digit deflators from \cite{nber}. Data preparation follows \cite{Keller2009} and \cite{mert}. Some issues regarding the Compustat dataset is that since the data is reported in the firm's financial statements, deflated output and input measures may not be completely capture firm's actual usage. Also, since this sample only contains publicly traded firms, it is only a fraction of all manufacturing firms in the US. Summary statistics for these deflated values are provided in Table 1. We present a series of output elasticity estimates in Table 2 which are illustrated graphically in Figures \ref{fig:31coef}, \ref{fig:32coef}, \ref{fig:33coef}, and \ref{fig:USallcoef}.
 
\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Estimates/US_Summary.tex}
\label{Tab:USsummary}
For each industry in the US sample, we see that the estimates of the capital elasticity is increasing in the firm size distribution and decreasing in the labor elasticity corresponding to industries 31 and 32. For industry 33 and the combined industries, the labor elasticity is an inverse U-shape; it increases quickly for low $\tau$, but then flattens out after $\tau=0.5$. In industries 31 and 32 only the QLP capital estimate is significantly different from the LP estimate. In industry 33 both labor and capital estimates are significantly different from the LP estimate after $\tau=0.25$. In each industry we compare the difference between QLP and QR estimates to test whether our model corrects for endogeneity from unobserved productivity. Bootstrap is used to construct confidence intervals of the difference between the two estimates. We find that there are significant differences between these estimates with the exception of estimates at $\tau=0.05, 0.1$ and $0.15$.\\

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/Coef_Plot_NAICS_31.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:31coef}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/Coef_Plot_NAICS_32.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:32coef}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/Coef_Plot_NAICS_33.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:33coef}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/Coef_Plot_NAICS_All.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:USallcoef}
\end{figure}

We use the estimates from the output elasticities to construct measures of returns to scale and capital intensity in Table 2. The results for returns to scale are puzzling as they are all significantly different from constant returns to scale. We can see in Industry 32 that returns to scale are generally decreasing in firm-size whereas this relationship is increasing in Industry 33. Previous papers that estimate returns to scale using the Compustat dataset such as \cite{Keller2009} and \cite{mert} show constant returns to scale using a gross-output production function. Therefore it is possible that the empirical value-added (deflated sales minus intermediate input expenditure) is a poor proxy for value-added in our model and that value-added biases the returns to scale estimates. Differences in returns to scale in value-added and gross-output production functions are explored by \cite{Basu1997}. We also report estimates of capital intensity measured by the ratio of capital to labor elasticity for each quantile. In each industry, capital intensity is increasing in firm-size. This result is consistent with previous findings such as \cite{Holmes2008}, \cite{Kumar1999} and \cite{mert}.


\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Estimates/US_Beta_Estimates.tex}

We also use our quantile production function estimates to construct measures of firm level productivity which we define as
\begin{equation}
\hat{w}_{it,\tau}=\exp(y_{it}-\hat{\beta_{k}}(\tau)k_{it}-\hat{\beta_{l}}(\tau)l_{it})
\end{equation}
We use these measured to compare productivity growth over time to LP estimates as well as an exercise to see if there is significant dispersion in the productivity distribution over the distribution of firm size. Figure \ref{fig:USpgrowth} reports average productivity for all US firms in the sample with the base year of the sample period set to 100. We can see that productivity growth was rapid in the beginning of the sample period but then declined after 1970 and increase again after 1980. Growth trends for each percentile of firm-size were similar although larger firms in this sample were more productive than smaller ones. Interestingly, the LP estimates are close to the productivity estimates for smaller firms at $\tau=0.1$. This suggests that there is significant heterogeneity in the conditional firm-size distribution that conditional mean estimates of productivity such as LP cannot capture.


\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/TFP_Plot.png}
\caption{Estimated average productivity over time for the US. Base productivity in 1961 is set to 100.}
\label{fig:USpgrowth}
\end{figure}

In Figure \ref{fig:USpdisp} we graph estimates of certain percentiles of log-productivity distribution over the firm-size distribution for each industry in our sample. In industry 31 and 33 log-productivity is decreasing for each percentile of firm-size. Log-productivity falls faster in industry 33 compared to industry 31 for small firms, but reverses for larger firms in each industry. Log-productivity for firms in industry 32 has an inverse U-shaped relationship. It is increasing for small firms, then somewhat stagnant for medium sized firms, but then falls for very large firms. In each industry, there is substantial heterogeneity in productivity dispersion after controlling for differences in firm-size. For example, in industry 31 small firms ($\tau=0.1$) in the 90th percentile of productivity are about 7.1 times more productive than firms in the 10th percentile of productivity. For large firms ($\tau=0.95$), this number is about six. This suggests that there could exist some heterogeneity in common productivity dispersion estimates, such as the 90/10 ratio we use here.

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/QTFP_plot.png}
\caption{Estimated log-productivity at different quantiles over the firm-size distribution}
\label{fig:USpdisp}
\end{figure}

We are also interested in examining the firm-size distribution over time and whether there are differences in within-firm and across firm technology heterogeneity. Figure \ref{fig:UStimecoef} plots estimates of the output elasticities over 5 year intervals. For labor elasticity, there is heterogeneity across the firm size distribution in the beginning of the sample period. Larger firms had greater estimates of labor elasticity than very small firms. This heterogeneity decreases up until 1980 when the relationship between firm size and labor elasticity reverses. At the end of our sample period, very large firms have smaller estimates of labor elasticity than very small firms. The estimates of capital elasticity appear to be increases, however there is no discernible relationship of these estimates across different firm sizes. 

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/US/Plots/Time_Plot.png}
\caption{Estimated values of production function coefficients over time estimated at 5 year intervals}
\label{fig:UStimecoef}
\end{figure}


%----------------------------------------------------------------------------------------

\subsection{Chilean Manufacturing}
This data comes from the census of Chilean manufacturing plants conducted by the Instituto Nacional de Estadist\'ica (INE). The sample is collected between 1979 and 1996 for firms with more than 10 employees. We divide our estimates into the three largest manufacturing industries: Food (ISIC 311), Fabricated Metals (ISIC 381), and Textiles (ISIC 321). We also aggregate the three industries with the other smaller industries to obtain estimates from the entire sample. Summary statistics for the data we use are provided in Table 3.

Figures \ref{fig:CHL311}, \ref{fig:CHL321}, and \ref{fig:CHL381} illustrate our estimates from our model compared to LP estimates as well as their differences to QR estimates. Aside from ISIC 311, the estimates for labor elasticity are decreasing, but not significantly different from the LP estimates. However, since these estimates are significantly different from the QR estimate suggests that our estimator corrects for the endogeneity bias from unobserved productivity. The estimates for capital elasticity are decreasing in ISIC 311 and ISIC 381, but mostly flat for ISIC 321 and all of the industries in the sample. In every industry except for ISIC 321 there are differences between the QLP and LP estimates as well as differences between the QR estimates. These results may suggest that the productivity contributes more to heterogeneity in the estimates than do differences in the rank of the ex-post shock. From Table 4, our estimates of returns to scale are more reasonable compared to the US estimates. Interestingly returns to scale decrease as firm-size increases. Capital intensity decreases in firm-size in ISIC 311 and increases in firm-size in the entire sample.


\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Estimates/CHL_Summary.tex}  

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/Coef_Plot_ISIC_311.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:CHL311}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/Coef_Plot_ISIC_321.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:CHL321}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/Coef_Plot_ISIC_381.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:CHL381}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/Coef_Plot_ISIC_All.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:CHLall}
\end{figure}

\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Estimates/CHL_Beta_Estimates.tex}

Figure \ref{fig:CHLpgrowth} reports average productivity for all Chilean plants in the sample with base period set to 100. Productivity decreases in the beginning of the 1980s but the increases for the rest of the sample period. The LP estimates show higher productivity than the larger firms at $\tau=0.9$ Figure \ref{fig:CHLpdisp} graphs the percentiles of log-productivity over the firm-size distribution for each large industry in Chile. In each industry, log-productivity is increasing in firm-size. Like the estimates in the US, there is heterogeneity in productivity dispersion. For example, in ISIC 381, small firms ($\tau=0.1$) in the 90th percentile of productivity are about more 10.8 times productive than firms in the 10th percentile of productivity. For large firms ($\tau=0.95$), this number is about 14.4. Lastly, Figure \ref{fig:CHLtimecoef} shows the time trends in output elasticities. The estimate of labor elasticity are high for each quantile of firm size and decreases steadily with the exception of small firms ($\tau=0.1$). The estimates for capital elasticities are large aside from $\tau=0.25$, but converge quickly after 1979. 

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/TFP_Plot.png}
\caption{Estimated average productivity over time for Chile. Base productivity in 1979 is set to 100.}
\label{fig:CHLpgrowth}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/QTFP_plot.png}
\caption{Estimated log-productivity at different quantiles over the firm-size distribution}
\label{fig:CHLpdisp}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Chile/Plots/Time_Plot.png}
\caption{Estimated values of production function coefficients over time estimated at 2 year intervals}
\label{fig:CHLtimecoef}
\end{figure}


%------------------------------------------------------------------------------------------------

\subsection{Colombian Manufacturing}
This data comes is from the Colombian manufacturing census conducted by the Departamento Administrativo Nacional de Estadistica. The sample is collected between 1977 and 1991 for firms with more than 10 employees. We divide our estimates into the three largest manufacturing industries: Food (ISIC 311), Apparel (ISIC 322), and Fabricated Metals (ISIC 381). As we did with the Chilean sample, we also aggregate the three industries with other smaller industries to obtain estimates from the entire sample of manufacturing plants. Summary statistics for this data is provided in Table 5.

\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Estimates/COL_Summary.tex}

Figures \ref{fig:COL311}, \ref{fig:COL321}, and \ref{fig:COL381} illustrate estimates from our model compared to the LP estimates as well as their differences from QR estimates. The first industry, ISIC 311, shows QLP estimates of both capital and labor elasticities significantly different from LP estimates. There are also differences between these estimates and QR estimates which suggests that this method shows heterogeneity in both firm size and productivity in this industry. In ISIC 322, only the QLP estimate of labor elasticity shows significant difference from the LP estimate as well as differences from the QR estimates. There is not much difference in the QLP estimates of capital when compared to LP and QR estimates. Similar results are also true for ISIC 381. With the industries combined, both QLP estimates of capital and labor are significantly different from LP and QR estimates. For each industry, these estimates show a common trend. Capital estimates tend to increase in firm-size whereas labor estimates tend to decrease.

Using these estimates we construct measures of returns to scale and capital intensity for each industry in Table 6. Most firms experience constant returns to scale or slightly decreasing returns to scale and we observe that returns to scale are decreasing in firm-size. The only noticeable trends in capital intensity appear in ISIC 311 and the combined sample which show decreasing relationship in firm-size in ISIC 311 and an increasing relationship in the combined sample.  

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/Coef_Plot_ISIC_311.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:COL311}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/Coef_Plot_ISIC_322.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:COL321}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/Coef_Plot_ISIC_381.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:COL381}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/Coef_Plot_ISIC_All.png}
\caption{Top row: Estimated values of production function coefficients and their point-wise 90\% confidence interval. Bottom row: Difference between QLP and quantile regression estimates and their 95\% confidence intervals.}
\label{fig:COLall}
\end{figure}

\input{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Estimates/COL_Beta_Estimates.tex}

Figure \ref{fig:COLpgrowth} reports average productivity for all Colombian plants in the sample with base period set to 100. Productivity decreases in the beginning of the sample period but then increases for the rest of the sample period after 1980 with some sharp periods of productivity decline and incline. Each percentile of firm size has similar productivity levels at the beginning of the sample period, but diverge after 1984. The LP estimates show just higher than productivity of small firms at $\tau=0.1$ Figure \ref{fig:COLpdisp} graphs the percentiles of log-productivity over the firm-size distribution for each large industry in Colombia. In each industry, log-productivity is increasing in firm-size. Like the estimates in the US and Chile, there is heterogeneity in productivity dispersion. For example, in ISIC 322, small firms ($\tau=0.1$) in the 90th percentile of productivity are about 4.9 times more productive than firms in the 10th percentile of productivity. For large firms ($\tau=0.95$), this number is about 6.7. Finally, Figure \ref{fig:COLtimecoef} shows the time trends in output elasticities. The estimate of labor elasticity are about 0.6 for each quantile of firm size and increases steadily until about 1981 then starts to decrease. At the end of the sample period there is more heterogeneity in these estimates. Capital elasticity estimates tend to decrease during the sample period for each quantile of firm size.

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/TFP_Plot.png}
\caption{Estimated average productivity over time for Colombia. Base productivity in 1978 is set to 100.}
\label{fig:COLpgrowth}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/QTFP_plot.png}
\caption{Estimated log-productivity at different quantiles over the firm-size distribution}
\label{fig:COLpdisp}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=12cm]{/Users/justindoty/Documents/Research/Dissertation/Production_QR_Proxy/Code/Empirical/Colombia/Plots/Time_Plot.png}
\caption{Estimated values of production function coefficients over time estimated at 2 year intervals}
\label{fig:COLtimecoef}
\end{figure}

\section{Conclusions} \label{conclusion}

We proposed a method that extends the intermediate input proxy variable approach to estimating quantiles of the conditional quantiles of firm production. The method is computationally attractive as it resembles the two-stage estimator introduced in the control function literature with conditional quantile restrictions in the first stage. As a result, practitioners are able to easily apply the proposed estimator to production function models where the data reveal significant heterogeneous output elasticities along the conditional firm-size distribution. We showed that identification conditions for second stage estimates based on conditional quantiles are not as straightforward as conditional mean moment restrictions in the presence of two unobservables. Using the concentrated moment approach of \cite{Ackerberg2015} appears to fix this issue.  We showed that this estimator works well in finite samples and showed that it captures heterogeneity in firm-size under different data generating processes. An application to widely used datasets from the US, Chile, and Colombia showed that in some industries, our estimator captures unobserved heterogeneity that the LP estimator does not.

Improvements and extensions of this estimator are currently being explored. For example, using a value-added production function may show more heterogeneity in estimates of elasticities and productivity than a gross-output production function. However, using a gross-output production function with an intermediate input proxy variable suffers from non-identification problems. Therefore, a structural value-added production function may be preferable. \cite{Kasahara2015} show how to modify OP/LP type moment conditions for a value-added production function from a gross-output production function. It would be interesting to explore whether those methods could be applied here. This paper also makes an interesting connection between the literature on production risk and quantile utility maximization. Currently, quantile utility maximization problems and estimation of these models are being studied by \cite{Castro2017} and \cite{qgmm} in the context of dynamic consumption problems. It would be interesting to explore a model for a firm who maximizes quantile utility of profits which could provide an alternative explanation for unobserved heterogeneity from quantile regression estimates.

This paper contributes to the growing literature on production functions with unobserved heterogeneity. We show that differences in firm-size correspond to the the rank of the ex-post shock. The control function approach used here restricts us from examining other dimensions of firm heterogeneity. For example, this approach only allows us to use a location shift model for productivity. The consequence of this is that estimated growth rates in productivity are the same across firm-size which may not be true in practice. Allowing richer distributional affects of productivity would be an interesting extension. This approach also restricts us from examining non-Hicks neutral productivity shocks factor-augmenting productivity. We are currently working on an extension of this paper to a non-separable model to address these last two points, but the estimator we propose here is computationally attractive and easy to implement in empirical research.    




\pagebreak
\newpage



%\section*{Appendix}
%\appendix
%\begin{Large}
%\noindent \textbf{A. Proof of the Theorems}
%\end{Large}

%\counterwithin{theorem}{section}
%\section{Proofs}





\bibliographystyle{ecca.bst}
\bibliography{references}




\end{document}